{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import networkx as nx\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "\n",
    "contents = urllib.request.urlopen(\"https://en.wikipedia.org/wiki/Historical_federal_electoral_districts_of_Canada\").read()\n",
    "\n",
    "section = wikipedia.WikipediaPage('Historical federal electoral districts of Canada')\n",
    "years = section.links\n",
    "\n",
    "regex = re.compile(\"(List of Canadian electoral districts)\")\n",
    "\n",
    "years = [s for s in years if regex.match(s)]\n",
    "#years = years[9:]\n",
    "years = years[-5:]\n",
    "\n",
    "\n",
    "# Construct a dict for the riding names for the entire set of ridings\n",
    "riding_dict = {}\n",
    "\n",
    "class RidingObject:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.eras = []\n",
    "        self.elections = []\n",
    "\n",
    "class Era:\n",
    "    def __init__(self, start, end, predecessors, successors):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.predecessors = predecessors\n",
    "        self.successors = successors\n",
    "\n",
    "    def add_dates(self, start, end):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "\n",
    "    def add_predecessors (self, predecessors):\n",
    "        self.predecessors = predecessors\n",
    "\n",
    "    def add_successors(self, successors):\n",
    "        self.successors = successors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Year:  List of Canadian electoral districts 1966–1976\nNumber of districts:  263\nYear:  List of Canadian electoral districts 1976–1987\nNumber of districts:  281\nYear:  List of Canadian electoral districts 1987–1996\nNumber of districts:  295\nYear:  List of Canadian electoral districts 1996–2003\nNumber of districts:  301\nYear:  List of Canadian electoral districts 2003–2013\nNumber of districts:  308\n"
    }
   ],
   "source": [
    "# Go through and obtain the riding names for every year\n",
    "for i in range(len(years)):#range(4): #range(len(years)):\n",
    "    year = years[i]\n",
    "    section = wikipedia.WikipediaPage(year)\n",
    "    html = section.html()\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # GET ELECTORAL DISTRICT NAMES\n",
    "    lists = soup.find_all(\"ul\")\n",
    "    lists.pop(0)\n",
    "    content = lists[0]\n",
    "\n",
    "    def getArticleTitles(ul_list):\n",
    "        content = ul_list.findChildren(\"li\")\n",
    "        return [getArticleTitle(article) for article in content]\n",
    "\n",
    "    def getArticleTitle(list_element):\n",
    "        return list_element.findChildren(\"a\" , recursive=False)[0].get(\"title\")\n",
    "\n",
    "    ridings_by_province = [getArticleTitles(list_element) for list_element in lists]\n",
    "\n",
    "    num_districts = 0\n",
    "    for district_list in ridings_by_province:\n",
    "        for riding in district_list:\n",
    "            riding_dict[riding] = RidingObject(riding)\n",
    "            num_districts += 1\n",
    "    \n",
    "    print(\"Year: \", year)\n",
    "    print(\"Number of districts: \", num_districts)\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of entries in dict:  705\nNumber of nodes in graph:  705\n"
    }
   ],
   "source": [
    "# Construct nodes for each member of the dict\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(riding_dict.items())\n",
    "\n",
    "print(\"Number of entries in dict: \", len(riding_dict))\n",
    "print(\"Number of nodes in graph: \", G.number_of_nodes())\n",
    "\n",
    "# Want to create a series of eras:\n",
    "# Want to extract predecessors, successors and dates for each era\n",
    "# Need to handle edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION DEFINITIONS\n",
    "\n",
    "# EXTRACT SUCCESSORS\n",
    "# TODO: handle case where predecessors are not explictly indicated (assume they are the previous successors)\n",
    "def scrape_table_information(soup):\n",
    "    # extract relevant table\n",
    "    table = None\n",
    "    for header in soup.find_all('h2'):\n",
    "        #valid_ids = [\"Members_of_Parliament\", \"Members of the Legislative Assembly\"]\n",
    "        \"\"\"\n",
    "        print(\"#################################\")\n",
    "        print(header)\n",
    "        print(\"#######\")\n",
    "        print(header.findChildren(\"span\", id=\"Members_of_the_Legislative_Assembly\"))\n",
    "        \"\"\"\n",
    "        if (header.findChildren(\"span\", id=\"Members_of_Parliament\")):# or header.findChildren(\"span\", id=\"Members_of_the_Legislative_Assembly_.2F_National_Assembly\")):\n",
    "            table = header.findNext('table')\n",
    "    if table is None:\n",
    "        for header in soup.find_all('h2'):\n",
    "        #valid_ids = [\"Members_of_Parliament\", \"Members of the Legislative Assembly\"]\n",
    "        #print(\"#################################\")\n",
    "        #print(header)\n",
    "        #print(header.findChildren(\"span\", id=\"Members_of_the_Legislative_Assembly\"))\n",
    "            if header.findChildren(\"span\", id=\"History\"):# or header.findChildren(\"span\", id=\"Members_of_the_Legislative_Assembly\")):\n",
    "                table = header.findNext('table')\n",
    "    if table is None:\n",
    "        return False\n",
    "\n",
    "    table_tds = table.find_all(\"td\", align=\"center\")\n",
    "\n",
    "    def check_inclusion(table_td):\n",
    "        if (table_td.parent.has_attr('bgcolor') and table_td.has_attr('bgcolor')):\n",
    "            return table_td.parent['bgcolor'] == '#F0F0F0' or table_td['bgcolor'] == '#F0F0F0'\n",
    "        elif table_td.parent.has_attr('bgcolor'):\n",
    "            return table_td.parent['bgcolor'] == '#F0F0F0'\n",
    "        elif table_td.has_attr('bgcolor'):\n",
    "            return table_td['bgcolor'] == '#F0F0F0'\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    table_tds = [table_td for table_td in table_tds if check_inclusion(table_td)]\n",
    "    parents = [table_td.parent for table_td in table_tds]\n",
    "    table_trs = table.find_all(\"tr\")\n",
    "\n",
    "    # an ERA consists of a start date, and end date a set of predecessors and a set of successors\n",
    "    dates_regex = re.compile(\"[0-9]{4}\\s?(\\-|\\–)\\s?[0-9]{4}\") # re.compile(\".*\")#\n",
    "    first_date_regex = re.compile(\"[0-9]{4}\")\n",
    "    #print(existence_sections[2])\n",
    "    eras = []\n",
    "    for existence_section in table_tds:\n",
    "        #print(\"EXISTENCE: \", existence_section)\n",
    "        # find start date\n",
    "        tr = existence_section.findNext(\"tr\")\n",
    "        \n",
    "        # if there is no next section, exit loop\n",
    "        if tr not in table_trs:\n",
    "            break\n",
    "\n",
    "        # handle case where riding is recreated\n",
    "        if existence_section.parent.next_sibling.next_sibling not in parents:\n",
    "            tds = tr.findChildren(\"td\", recursive=False)\n",
    "            td_text = [td.get_text() for td in tds]\n",
    "            next_dates = list(filter(dates_regex.search, td_text))\n",
    "            start_date = first_date_regex.findall(next_dates[0])[0]\n",
    "\n",
    "            # find predecessors\n",
    "            origin = existence_section.find_all(\"b\")[0]\n",
    "            contents = origin.contents\n",
    "            #TODO: may want to verify here that created word appears here\n",
    "            children = origin.findChildren(\"a\", recursive=False)\n",
    "            if (len(children) == 0):\n",
    "                predecessor_titles = [contents[0]]\n",
    "            else:\n",
    "                predecessor_titles = [child.get(\"title\") for child in children]\n",
    "\n",
    "            # TODO: verify that a name has been found\n",
    "            #print(\"predecessor titles now: \", predecessor_titles)\n",
    "\n",
    "            # find sibling section\n",
    "            partner = existence_section.findNext(\"td\", align=\"center\")\n",
    "            print(partner)\n",
    "            if partner is None or partner not in table_tds:\n",
    "                last_dates = table_trs[-1]\n",
    "                tds = last_dates.findChildren(\"td\", recursive=False)\n",
    "\n",
    "                td_text = [td.get_text() for td in tds]\n",
    "                print(\"HERE\")\n",
    "                print(\"td: \", td_text)\n",
    "                next_dates = list(filter(first_date_regex.search, td_text))\n",
    "                end_date = first_date_regex.findall(next_dates[0])[-1]\n",
    "                successor_titles = [\"None found\"]\n",
    "            else:\n",
    "                tds = partner.parent.findPrevious(\"tr\").findChildren(\"td\", recursive=False)\n",
    "                td_text = [td.get_text() for td in tds]\n",
    "                next_dates = list(filter(dates_regex.search, td_text))\n",
    "                end_date = first_date_regex.findall(next_dates[0])[-1]\n",
    "\n",
    "                # find successors\n",
    "                origin = partner.find_all(\"b\")[0]\n",
    "                contents = origin.contents\n",
    "                #TODO: may want to verify here that created word appears here\n",
    "                children = origin.findChildren(\"a\", recursive=False)\n",
    "                if (len(children) == 0):\n",
    "                    successor_titles = [contents[0]]\n",
    "                else:\n",
    "                    successor_titles = [child.get(\"title\") for child in children]\n",
    "\n",
    "                # handle case of renaming\n",
    "                if (len(successor_titles) == 0):\n",
    "                    print(\"Well shit\")\n",
    "            \n",
    "            # create era\n",
    "            print(\"Start date: \", start_date)\n",
    "            print(\"End date: \", end_date)\n",
    "            print(\"Predecessors: \", predecessor_titles)\n",
    "            print(\"Successors: \", successor_titles)\n",
    "            eras.append(Era(start_date, end_date, predecessor_titles, successor_titles))\n",
    "        else:\n",
    "            print(\"Riding re-created\")\n",
    "\n",
    "    #print(following_dates)\n",
    "    #print(table)\n",
    "\n",
    "    #terms = [\"redistributed\", \"merged\", \"abolished\", \"dissolved\", \"amalgamated\", \"re-distributed\"]\n",
    "\n",
    "    return eras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "#########################################################\nCardigan (electoral district)  with index  0 / 705\nNone\nHERE\ntd:  [' 43rd ', '\\xa02019–present']\nStart date:  1968\nEnd date:  2019\nPredecessors:  [\"King's (Prince Edward Island electoral district)\", \"Queen's (Prince Edward Island electoral district)\"]\nSuccessors:  ['None found']\nRunning percentage:  100.0\nPercentage of ridings with at least one identified successor:  100.0 %\n"
    }
   ],
   "source": [
    "# LOOP THROUGH AND SCRAPE DATA\n",
    "total = 0\n",
    "approach_1 = 0\n",
    "approach_2 = 0\n",
    "electoral_districts = list(riding_dict.keys())\n",
    "\n",
    "# Process districts and extract successors\n",
    "with open('electoral_district_successors.csv', 'w', newline='') as successor_file:\n",
    "    successor_writer = csv.writer(successor_file)\n",
    "    num_districts = len(electoral_districts)\n",
    "    \n",
    "    for i in range(num_districts):\n",
    "        article_title = electoral_districts[i]\n",
    "        #article_title = \"Cardigan (electoral district)\"\n",
    "\n",
    "        print(\"#########################################################\")\n",
    "        print(article_title, \" with index \", i, \"/\", num_districts)\n",
    "\n",
    "       # if (i != 2 and i != 7):\n",
    "        riding_object = riding_dict.get(article_title)\n",
    "\n",
    "        # Extract dates and successors\n",
    "        #bad_names = [\"Brant North\", \"Brant South\"]\n",
    "        if (article_title not in bad_names):\n",
    "            summary = wikipedia.WikipediaPage(article_title).summary\n",
    "\n",
    "            page = wikipedia.WikipediaPage(article_title)\n",
    "            html = page.html()\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            eras = scrape_table_information(soup)\n",
    "\n",
    "            if (eras):\n",
    "                riding_object.eras = eras\n",
    "                riding_object.approach = \"Table approach\"\n",
    "                approach_1 += 1\n",
    "            else:\n",
    "                print(\"FUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUck\")\n",
    "            \"\"\"\n",
    "            else:\n",
    "                eras = scrape_non_table_information(article_title)\n",
    "                riding_object.approach = \"Summary approach\"\n",
    "                approach_2 += 1\n",
    "            \"\"\"\n",
    "        total += 1\n",
    "        print(\"Running percentage: \", 100*approach_1/total)\n",
    "        \n",
    "        successor_contents = [article_title] + [(era.start, era.end, era.predecessors, era.successors) for era in eras]\n",
    "        successor_writer.writerow(successor_contents)\n",
    "        #break\n",
    "print(\"Percentage of ridings with at least one identified successor: \", 100*(approach_1 + approach_2)/total, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_non_table_information(soup):\n",
    "    all_paragraphs = soup.find_all(\"p\")\n",
    "    #TODO: concatenate all contents\n",
    "    contents = all_paragraphs[0].contents\n",
    "    sliced_contents = contents\n",
    "\n",
    "    def extract_titles(keywords):\n",
    "        content_validator = re.compile(\"\\.?[^\\.]*%s[^\\.]*\" % '|'.join(predecessor_terms))\n",
    "        index = -1\n",
    "        for paragraph in all_paragraphs:\n",
    "            contents = paragraph.contents\n",
    "            sliced_contents = contents\n",
    "            for idx, element in enumerate(contents):\n",
    "                if (isinstance(element, str) and content_validator.search(element)):\n",
    "                    index = idx\n",
    "                    sliced_contents = contents[index + 1:]\n",
    "                    #print(sliced_contents)\n",
    "            if index > -1:\n",
    "                break\n",
    "        content_validator = re.compile(\".*\\..*\")\n",
    "        for idx, element in enumerate(sliced_contents):\n",
    "            if (isinstance(element, str) and content_validator.search(element)):\n",
    "                index = idx\n",
    "                sliced_contents = sliced_contents[:index]\n",
    "        # Filter children for valid electoral districts\n",
    "        children = paragraph.findChildren(\"a\", recursive=False)\n",
    "        relevant_children = [child for child in children if child in sliced_contents]\n",
    "        #print(relevant_children)\n",
    "        valid_titles = list(riding_dict.keys())\n",
    "        titles = [child.get(\"title\") for child in relevant_children]\n",
    "        return titles\n",
    "    \n",
    "    # find predecessors, if any\n",
    "    predecessor_terms = [\"created\"]\n",
    "    predecessor_titles = extract_titles(predecessor_terms)\n",
    "    \n",
    "    # find successors, if any\n",
    "\n",
    "    # find first occurence of keyword in paragraph\n",
    "    successor_terms = [\"redistributed\", \"merged\", \"abolished\", \"dissolved\", \"amalgamated\", \"re-distributed\"]\n",
    "    successor_titles = extract_titles(predecessor_terms)\n",
    "\n",
    "    # find dates of existence\n",
    "    start_date = \"Not implemented\"\n",
    "    end_date = \"Not implemented\"\n",
    "\n",
    "    # construct simple era\n",
    "    eras = [Era(start_date, end_date, predecessor_titles, successor_titles)]\n",
    "\n",
    "    print(\"################\")\n",
    "    print(\"Article title: \", article_title)\n",
    "    print(\"Found successors: \", titles)\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\ntotal = 0\\nsuccessful = 0\\n\\nwith open(\\'electoral_district_predecessors.csv\\', \\'w\\', newline=\\'\\') as predecessor_file:\\n    predecessor_writer = csv.writer(predecessor_file)\\n    \\n    for i in range(len(electoral_districts)):\\n        article_title = electoral_districts[i]\\n        riding_object = riding_dict.get(article_title)\\n        predecessors = riding_object.predecessors\\n\\n        if (len(predecessors) > 0):\\n            successful += 1\\n        \\n        if (len(predecessors) == 0):\\n            predecessors = [\"None found\"]\\n        \\n        predecessor_contents = [article_title] + predecessors\\n        predecessor_writer.writerow(predecessor_contents)\\n\\n        total += 1\\n        break\\n\\nprint(\"Percentage of ridings with at least one identified predecessor: \", 100*successful/total, \"%\")\\n'"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "\"\"\"\n",
    "total = 0\n",
    "successful = 0\n",
    "\n",
    "with open('electoral_district_predecessors.csv', 'w', newline='') as predecessor_file:\n",
    "    predecessor_writer = csv.writer(predecessor_file)\n",
    "    \n",
    "    for i in range(len(electoral_districts)):\n",
    "        article_title = electoral_districts[i]\n",
    "        riding_object = riding_dict.get(article_title)\n",
    "        predecessors = riding_object.predecessors\n",
    "\n",
    "        if (len(predecessors) > 0):\n",
    "            successful += 1\n",
    "        \n",
    "        if (len(predecessors) == 0):\n",
    "            predecessors = [\"None found\"]\n",
    "        \n",
    "        predecessor_contents = [article_title] + predecessors\n",
    "        predecessor_writer.writerow(predecessor_contents)\n",
    "\n",
    "        total += 1\n",
    "        break\n",
    "\n",
    "print(\"Percentage of ridings with at least one identified predecessor: \", 100*successful/total, \"%\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('elections': conda)",
   "language": "python",
   "name": "python38264bitelectionsconda9a5b9d1cf3d74687b599c4877bffd1c6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}