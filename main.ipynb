{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import networkx as nx\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "\n",
    "contents = urllib.request.urlopen(\"https://en.wikipedia.org/wiki/Historical_federal_electoral_districts_of_Canada\").read()\n",
    "\n",
    "section = wikipedia.WikipediaPage('Historical federal electoral districts of Canada')\n",
    "years = section.links\n",
    "\n",
    "regex = re.compile(\"(List of Canadian electoral districts)\")\n",
    "\n",
    "years = [s for s in years if regex.match(s)]\n",
    "#years = years[9:]\n",
    "years = years[-5:]\n",
    "\n",
    "\n",
    "# Construct a dict for the riding names for the entire set of ridings\n",
    "riding_dict = {}\n",
    "\n",
    "class RidingObject:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.eras = []\n",
    "        self.elections = []\n",
    "\n",
    "class Era:\n",
    "    def __init__(self, start, end, predecessors, successors):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.predecessors = predecessors\n",
    "        self.successors = successors\n",
    "\n",
    "    def add_dates(self, start, end):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "\n",
    "    def add_predecessors (self, predecessors):\n",
    "        self.predecessors = predecessors\n",
    "\n",
    "    def add_successors(self, successors):\n",
    "        self.successors = successors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Year:  List of Canadian electoral districts 1966–1976\nNumber of districts:  263\nYear:  List of Canadian electoral districts 1976–1987\nNumber of districts:  281\nYear:  List of Canadian electoral districts 1987–1996\nNumber of districts:  295\nYear:  List of Canadian electoral districts 1996–2003\nNumber of districts:  301\nYear:  List of Canadian electoral districts 2003–2013\nNumber of districts:  308\n"
    }
   ],
   "source": [
    "# Go through and obtain the riding names for every year\n",
    "for i in range(len(years)):#range(4): #range(len(years)):\n",
    "    year = years[i]\n",
    "    section = wikipedia.WikipediaPage(year)\n",
    "    html = section.html()\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # GET ELECTORAL DISTRICT NAMES\n",
    "    lists = soup.find_all(\"ul\")\n",
    "    lists.pop(0)\n",
    "    content = lists[0]\n",
    "\n",
    "    def getArticleTitles(ul_list):\n",
    "        content = ul_list.findChildren(\"li\")\n",
    "        return [getArticleTitle(article) for article in content]\n",
    "\n",
    "    def getArticleTitle(list_element):\n",
    "        return list_element.findChildren(\"a\" , recursive=False)[0].get(\"title\")\n",
    "\n",
    "    ridings_by_province = [getArticleTitles(list_element) for list_element in lists]\n",
    "\n",
    "    num_districts = 0\n",
    "    for district_list in ridings_by_province:\n",
    "        for riding in district_list:\n",
    "            riding_dict[riding] = RidingObject(riding)\n",
    "            num_districts += 1\n",
    "    \n",
    "    print(\"Year: \", year)\n",
    "    print(\"Number of districts: \", num_districts)\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of entries in dict:  705\nNumber of nodes in graph:  705\n"
    }
   ],
   "source": [
    "# Construct nodes for each member of the dict\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(riding_dict.items())\n",
    "\n",
    "print(\"Number of entries in dict: \", len(riding_dict))\n",
    "print(\"Number of nodes in graph: \", G.number_of_nodes())\n",
    "\n",
    "# Want to create a series of eras:\n",
    "# Want to extract predecessors, successors and dates for each era\n",
    "# Need to handle edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION DEFINITIONS\n",
    "\n",
    "# EXTRACT SUCCESSORS\n",
    "# TODO: handle case where predecessors are not explictly indicated (assume they are the previous successors)\n",
    "def scrape_table_information(soup):\n",
    "    # extract relevant table\n",
    "    table = None\n",
    "    for header in soup.find_all('h2'):\n",
    "        #valid_ids = [\"Members_of_Parliament\", \"Members of the Legislative Assembly\"]\n",
    "        \"\"\"\n",
    "        print(\"#################################\")\n",
    "        print(header)\n",
    "        print(\"#######\")\n",
    "        print(header.findChildren(\"span\", id=\"Members_of_the_Legislative_Assembly\"))\n",
    "        \"\"\"\n",
    "        if (header.findChildren(\"span\", id=\"Members_of_Parliament\")):# or header.findChildren(\"span\", id=\"Members_of_the_Legislative_Assembly_.2F_National_Assembly\")):\n",
    "            table = header.findNext('table')\n",
    "    if table is None:\n",
    "        for header in soup.find_all('h2'):\n",
    "        #valid_ids = [\"Members_of_Parliament\", \"Members of the Legislative Assembly\"]\n",
    "        #print(\"#################################\")\n",
    "        #print(header)\n",
    "        #print(header.findChildren(\"span\", id=\"Members_of_the_Legislative_Assembly\"))\n",
    "            if header.findChildren(\"span\", id=\"History\"):# or header.findChildren(\"span\", id=\"Members_of_the_Legislative_Assembly\")):\n",
    "                table = header.findNext('table')\n",
    "    if table is None:\n",
    "        return False\n",
    "\n",
    "    table_tds = table.find_all(\"td\", align=\"center\")\n",
    "\n",
    "    def check_inclusion(table_td):\n",
    "        if (table_td.parent.has_attr('bgcolor') and table_td.has_attr('bgcolor')):\n",
    "            return table_td.parent['bgcolor'] == '#F0F0F0' or table_td['bgcolor'] == '#F0F0F0'\n",
    "        elif table_td.parent.has_attr('bgcolor'):\n",
    "            return table_td.parent['bgcolor'] == '#F0F0F0'\n",
    "        elif table_td.has_attr('bgcolor'):\n",
    "            return table_td['bgcolor'] == '#F0F0F0'\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    table_tds = [table_td for table_td in table_tds if check_inclusion(table_td)]\n",
    "    parents = [table_td.parent for table_td in table_tds]\n",
    "    table_trs = table.find_all(\"tr\")\n",
    "\n",
    "    # an ERA consists of a start date, and end date a set of predecessors and a set of successors\n",
    "    dates_regex = re.compile(\"[0-9]{4}\\s?(\\-|\\–)\\s?[0-9]{4}\") # re.compile(\".*\")#\n",
    "    first_date_regex = re.compile(\"[0-9]{4}\")\n",
    "    #print(existence_sections[2])\n",
    "    eras = []\n",
    "    for existence_section in table_tds:\n",
    "        #print(\"EXISTENCE: \", existence_section)\n",
    "        # find start date\n",
    "        tr = existence_section.findNext(\"tr\")\n",
    "        \n",
    "        # if there is no next section, exit loop\n",
    "        if tr not in table_trs:\n",
    "            break\n",
    "\n",
    "        # handle case where riding is recreated\n",
    "        if existence_section.parent.next_sibling.next_sibling not in parents:\n",
    "            tds = tr.findChildren(\"td\", recursive=False)\n",
    "            td_text = [td.get_text() for td in tds]\n",
    "            next_dates = list(filter(dates_regex.search, td_text))\n",
    "            start_date = first_date_regex.findall(next_dates[0])[0]\n",
    "\n",
    "            # find predecessors\n",
    "            origin = existence_section.find_all(\"b\")[0]\n",
    "            contents = origin.contents\n",
    "            #TODO: may want to verify here that created word appears here\n",
    "            children = origin.findChildren(\"a\", recursive=False)\n",
    "            if (len(children) == 0):\n",
    "                predecessor_titles = [contents[0]]\n",
    "            else:\n",
    "                predecessor_titles = [child.get(\"title\") for child in children]\n",
    "\n",
    "            # TODO: verify that a name has been found\n",
    "            #print(\"predecessor titles now: \", predecessor_titles)\n",
    "\n",
    "            # find sibling section\n",
    "            partner = existence_section.findNext(\"td\", align=\"center\")\n",
    "            if partner is None or partner not in table_tds:\n",
    "                last_dates = table_trs[-1]\n",
    "\n",
    "                td_text = [td.get_text() for td in tds]\n",
    "                next_dates = list(filter(dates_regex.search, td_text))\n",
    "                end_date = first_date_regex.findall(next_dates[0])[-1]\n",
    "                successor_titles = [\"None found\"]\n",
    "            else:\n",
    "                tds = partner.parent.findPrevious(\"tr\").findChildren(\"td\", recursive=False)\n",
    "                td_text = [td.get_text() for td in tds]\n",
    "                next_dates = list(filter(dates_regex.search, td_text))\n",
    "                end_date = first_date_regex.findall(next_dates[0])[-1]\n",
    "\n",
    "                # find successors\n",
    "                origin = partner.find_all(\"b\")[0]\n",
    "                contents = origin.contents\n",
    "                #TODO: may want to verify here that created word appears here\n",
    "                children = origin.findChildren(\"a\", recursive=False)\n",
    "                if (len(children) == 0):\n",
    "                    successor_titles = [contents[0]]\n",
    "                else:\n",
    "                    successor_titles = [child.get(\"title\") for child in children]\n",
    "\n",
    "                # handle case of renaming\n",
    "                if (len(successor_titles) == 0):\n",
    "                    print(\"Well shit\")\n",
    "            \n",
    "            # create era\n",
    "            print(\"Start date: \", start_date)\n",
    "            print(\"End date: \", end_date)\n",
    "            print(\"Predecessors: \", predecessor_titles)\n",
    "            print(\"Successors: \", successor_titles)\n",
    "            eras.append(Era(start_date, end_date, predecessor_titles, successor_titles))\n",
    "        else:\n",
    "            print(\"Riding re-created\")\n",
    "\n",
    "    #print(following_dates)\n",
    "    #print(table)\n",
    "\n",
    "    #terms = [\"redistributed\", \"merged\", \"abolished\", \"dissolved\", \"amalgamated\", \"re-distributed\"]\n",
    "\n",
    "    return eras\n",
    "\n",
    "def scrape_non_table_information(soup):\n",
    "    all_paragraphs = soup.find_all(\"p\")\n",
    "    #TODO: concatenate all contents\n",
    "    contents = all_paragraphs[0].contents\n",
    "    sliced_contents = contents\n",
    "\n",
    "    def extract_titles(keywords):\n",
    "        content_validator = re.compile(\"\\.?[^\\.]*%s[^\\.]*\" % '|'.join(predecessor_terms))\n",
    "        index = -1\n",
    "        for paragraph in all_paragraphs:\n",
    "            contents = paragraph.contents\n",
    "            sliced_contents = contents\n",
    "            for idx, element in enumerate(contents):\n",
    "                if (isinstance(element, str) and content_validator.search(element)):\n",
    "                    index = idx\n",
    "                    sliced_contents = contents[index + 1:]\n",
    "                    #print(sliced_contents)\n",
    "            if index > -1:\n",
    "                break\n",
    "        content_validator = re.compile(\".*\\..*\")\n",
    "        for idx, element in enumerate(sliced_contents):\n",
    "            if (isinstance(element, str) and content_validator.search(element)):\n",
    "                index = idx\n",
    "                sliced_contents = sliced_contents[:index]\n",
    "        # Filter children for valid electoral districts\n",
    "        children = paragraph.findChildren(\"a\", recursive=False)\n",
    "        relevant_children = [child for child in children if child in sliced_contents]\n",
    "        #print(relevant_children)\n",
    "        valid_titles = list(riding_dict.keys())\n",
    "        titles = [child.get(\"title\") for child in relevant_children]\n",
    "        return titles\n",
    "    \n",
    "    # find predecessors, if any\n",
    "    predecessor_terms = [\"created\"]\n",
    "    predecessor_titles = extract_titles(predecessor_terms)\n",
    "    \n",
    "    # find successors, if any\n",
    "\n",
    "    # find first occurence of keyword in paragraph\n",
    "    successor_terms = [\"redistributed\", \"merged\", \"abolished\", \"dissolved\", \"amalgamated\", \"re-distributed\"]\n",
    "    successor_titles = extract_titles(predecessor_terms)\n",
    "\n",
    "    # find dates of existence\n",
    "    start_date = \"Not implemented\"\n",
    "    end_date = \"Not implemented\"\n",
    "\n",
    "    # construct simple era\n",
    "    eras = [Era(start_date, end_date, predecessor_titles, successor_titles)]\n",
    "\n",
    "    print(\"################\")\n",
    "    print(\"Article title: \", article_title)\n",
    "    print(\"Found successors: \", titles)\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "#########################################################\nBonavista—Trinity—Conception  with index  0\nStart date:  1968\nEnd date:  2004\nPredecessors:  ['Bonavista—Twillingate', 'Trinity—Conception']\nSuccessors:  ['Avalon (electoral district)', 'Bonavista—Gander—Grand Falls—Windsor', \"Random—Burin—St. George's\"]\nRunning percentage:  100.0\n#########################################################\nBurin—Burgeo  with index  1\nStart date:  1949\nEnd date:  1979\nPredecessors:  Burin—Burgeo\nSuccessors:  [\"Burin—St. George's\"]\nRunning percentage:  100.0\n#########################################################\nGander—Twillingate  with index  2\nStart date:  1968\nEnd date:  1988\nPredecessors:  ['Bonavista—Twillingate', 'Grand Falls—White Bay—Labrador']\nSuccessors:  ['Bonavista—Trinity—Conception', 'Gander—Grand Falls']\nRunning percentage:  100.0\n#########################################################\nGrand Falls—White Bay—Labrador  with index  3\nStart date:  1949\nEnd date:  1953\nPredecessors:  Grand Falls—White Bay\nSuccessors:  Grand Falls—White Bay—Labrador\nStart date:  1953\nEnd date:  1988\nPredecessors:  Grand Falls—White Bay—Labrador\nSuccessors:  Labrador\nStart date:  1988\nEnd date:  1993\nPredecessors:  Labrador\nSuccessors:  ['None found']\nRunning percentage:  100.0\n#########################################################\nHumber—St. George's—St. Barbe  with index  4\nStart date:  1968\nEnd date:  1979\nPredecessors:  [\"Humber—St. George's\", 'Grand Falls—White Bay—Labrador']\nSuccessors:  ['Humber—Port au Port—St. Barbe', \"Burin—St. George's\"]\nRunning percentage:  100.0\n#########################################################\nSt. John's East  with index  5\nStart date:  1949\nEnd date:  2004\nPredecessors:  St. John's East\nSuccessors:  St. John's North\nStart date:  2004\nEnd date:  2006\nPredecessors:  St. John's North\nSuccessors:  St. John's East\nStart date:  2006\nEnd date:  2008\nPredecessors:  St. John's East\nSuccessors:  ['None found']\nRunning percentage:  100.0\n#########################################################\nSt. John's West  with index  6\nStart date:  1949\nEnd date:  2004\nPredecessors:  St. John's West\nSuccessors:  ['Avalon (electoral district)', \"St. John's South—Mount Pearl\"]\nRunning percentage:  100.0\n#########################################################\nAnnapolis Valley (electoral district)  with index  7\nStart date:  1968\nEnd date:  1979\nPredecessors:  ['Colchester—Hants', 'Digby—Annapolis—Kings']\nSuccessors:  Annapolis Valley—Hants\nStart date:  1979\nEnd date:  1997\nPredecessors:  Annapolis Valley—Hants\nSuccessors:  Kings—Hants\nStart date:  1997\nEnd date:  2000\nPredecessors:  Kings—Hants\nSuccessors:  ['None found']\nRunning percentage:  100.0\n#########################################################\nCape Breton Highlands—Canso  with index  8\nStart date:  1968\nEnd date:  1997\nPredecessors:  ['Antigonish—Guysborough', 'Inverness—Richmond', 'North Cape Breton and Victoria']\nSuccessors:  [\"Bras d'Or (electoral district)\", 'Pictou—Antigonish—Guysborough', 'Sydney—Victoria']\nRunning percentage:  100.0\n#########################################################\nCape Breton—East Richmond  with index  9\nStart date:  1968\nEnd date:  1997\nPredecessors:  ['Cape Breton South (federal electoral district)', 'Inverness—Richmond', 'North Cape Breton and Victoria']\nSuccessors:  [\"Bras d'Or (electoral district)\", 'Sydney—Victoria']\nRunning percentage:  100.0\n#########################################################\nCape Breton—The Sydneys  with index  10\nStart date:  1968\nEnd date:  1997\nPredecessors:  ['Cape Breton South (federal electoral district)']\nSuccessors:  ['Sydney—Victoria']\nRunning percentage:  100.0\n#########################################################\nCentral Nova  with index  11\nStart date:  1968\nEnd date:  1997\nPredecessors:  ['Antigonish—Guysborough', 'Colchester—Hants', 'Pictou (electoral district)']\nSuccessors:  ['Pictou—Antigonish—Guysborough', 'Sackville—Eastern Shore']\nRiding re-created\nStart date:  2004\nEnd date:  2006\nPredecessors:  ['Pictou—Antigonish—Guysborough', 'Sackville—Musquodoboit Valley—Eastern Shore']\nSuccessors:  ['None found']\nRunning percentage:  100.0\n#########################################################\nCumberland—Colchester North  with index  12\nStart date:  1968\nEnd date:  1979\nPredecessors:  ['Cumberland (electoral district)', 'Colchester—Hants']\nSuccessors:  Cumberland—Colchester\nStart date:  1979\nEnd date:  2004\nPredecessors:  Cumberland—Colchester\nSuccessors:  North Nova\nStart date:  2004\nEnd date:  2006\nPredecessors:  North Nova\nSuccessors:  Cumberland—Colchester—Musquodoboit Valley\nStart date:  2006\nEnd date:  2015\nPredecessors:  Cumberland—Colchester—Musquodoboit Valley\nSuccessors:  Cumberland—Colchester\nStart date:  2015\nEnd date:  2019\nPredecessors:  Cumberland—Colchester\nSuccessors:  ['None found']\nRunning percentage:  100.0\n#########################################################\nDartmouth—Halifax East  with index  13\nStart date:  1968\nEnd date:  1988\nPredecessors:  ['Halifax (electoral district)']\nSuccessors:  Dartmouth\nStart date:  1988\nEnd date:  2004\nPredecessors:  Dartmouth\nSuccessors:  Dartmouth—Cole Harbour\nStart date:  2004\nEnd date:  2006\nPredecessors:  Dartmouth—Cole Harbour\nSuccessors:  ['None found']\nRunning percentage:  100.0\n#########################################################\nHalifax (electoral district)  with index  14\nStart date:  1867\nEnd date:  1869\nPredecessors:  Halifax\nSuccessors:  ['None found']\nRunning percentage:  100.0\n#########################################################\nHalifax—East Hants  with index  15\nStart date:  1968\nEnd date:  1979\nPredecessors:  ['Colchester—Hants']\nSuccessors:  ['Annapolis Valley—Hants', 'Halifax (electoral district)', 'Halifax West']\nRunning percentage:  100.0\n#########################################################\nSouth Shore (electoral district)  with index  16\nStart date:  1968\nEnd date:  2004\nPredecessors:  ['Queens—Lunenburg', 'Shelburne—Yarmouth—Clare']\nSuccessors:  South Shore—St. Margaret's\nStart date:  2004\nEnd date:  2015\nPredecessors:  South Shore—St. Margaret's\nSuccessors:  South Shore—St. Margarets\nStart date:  2015\nEnd date:  2019\nPredecessors:  South Shore—St. Margarets\nSuccessors:  ['None found']\nRunning percentage:  100.0\n#########################################################\nSouth Western Nova  with index  17\nStart date:  1968\nEnd date:  1979\nPredecessors:  ['Digby—Annapolis—Kings', 'Shelburne—Yarmouth—Clare']\nSuccessors:  South West Nova\nStart date:  1979\nEnd date:  1997\nPredecessors:  South West Nova\nSuccessors:  West Nova\nStart date:  1997\nEnd date:  2000\nPredecessors:  West Nova\nSuccessors:  ['None found']\nRunning percentage:  100.0\n#########################################################\nCardigan (electoral district)  with index  18\nStart date:  1968\nEnd date:  1972\nPredecessors:  [\"King's (Prince Edward Island electoral district)\", \"Queen's (Prince Edward Island electoral district)\"]\nSuccessors:  ['None found']\nRunning percentage:  100.0\n#########################################################\nEgmont (electoral district)  with index  19\nStart date:  1968\nEnd date:  1972\nPredecessors:  ['Prince (electoral district)']\nSuccessors:  ['None found']\nRunning percentage:  100.0\n#########################################################\nHillsborough (electoral district)  with index  20\nStart date:  1968\nEnd date:  2004\nPredecessors:  [\"Queen's (Prince Edward Island electoral district)\"]\nSuccessors:  Charlottetown\nStart date:  2004\nEnd date:  2006\nPredecessors:  Charlottetown\nSuccessors:  ['None found']\nRunning percentage:  100.0\n#########################################################\nMalpeque (electoral district)  with index  21\nStart date:  1968\nEnd date:  1972\nPredecessors:  ['Prince (electoral district)', \"Queen's (Prince Edward Island electoral district)\"]\nSuccessors:  ['None found']\nRunning percentage:  100.0\n#########################################################\nCarleton—Charlotte  with index  22\nStart date:  1968\nEnd date:  1997\nPredecessors:  ['Charlotte (electoral district)', 'Victoria—Carleton', 'St. John—Albert', 'York—Sunbury']\nSuccessors:  ['Charlotte (electoral district)', 'Tobique—Mactaquac']\nRunning percentage:  100.0\n#########################################################\nFundy—Royal  with index  23\nStart date:  1917\nEnd date:  1968\nPredecessors:  Royal\nSuccessors:  Fundy—Royal\nStart date:  1968\nEnd date:  2004\nPredecessors:  Fundy—Royal\nSuccessors:  Fundy Royal\nStart date:  2004\nEnd date:  2006\nPredecessors:  Fundy Royal\nSuccessors:  ['None found']\nRunning percentage:  100.0\n#########################################################\nGloucester (electoral district)  with index  24\nStart date:  1867\nEnd date:  1993\nPredecessors:  Gloucester\nSuccessors:  Acadie—Bathurst\nStart date:  1993\nEnd date:  1997\nPredecessors:  Acadie—Bathurst\nSuccessors:  ['None found']\nRunning percentage:  100.0\n#########################################################\nMadawaska—Victoria  with index  25\nStart date:  1968\nEnd date:  1997\nPredecessors:  ['Restigouche—Madawaska', 'Victoria—Carleton']\nSuccessors:  ['Madawaska—Restigouche', 'Tobique—Mactaquac']\nRunning percentage:  100.0\n#########################################################\nMoncton (electoral district)  with index  26\nStart date:  1968\nEnd date:  1997\nPredecessors:  ['Westmorland (electoral district)']\nSuccessors:  Moncton—Riverview—Dieppe\nStart date:  1997\nEnd date:  2000\nPredecessors:  Moncton—Riverview—Dieppe\nSuccessors:  ['None found']\nRunning percentage:  100.0\n#########################################################\nNorthumberland—Miramichi  with index  27\nStart date:  1867\nEnd date:  1957\nPredecessors:  Northumberland\nSuccessors:  Northumberland—Miramichi\nStart date:  1957\nEnd date:  1988\nPredecessors:  Northumberland—Miramichi\nSuccessors:  Miramichi\nStart date:  1988\nEnd date:  2015\nPredecessors:  Miramichi\nSuccessors:  ['Miramichi—Grand Lake', 'Acadie—Bathurst', 'Madawaska—Restigouche']\nRunning percentage:  100.0\n#########################################################\nRestigouche (electoral district)  with index  28\nStart date:  1867\nEnd date:  1915\nPredecessors:  Restigouche\nSuccessors:  ['Restigouche—Madawaska']\nRiding re-created\nStart date:  1968\nEnd date:  1993\nPredecessors:  ['Restigouche—Madawaska']\nSuccessors:  Restigouche—Chaleur\nStart date:  1993\nEnd date:  1997\nPredecessors:  Restigouche—Chaleur\nSuccessors:  ['Madawaska—Restigouche']\nRunning percentage:  100.0\n#########################################################\nSaint John—Lancaster  with index  29\nFUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUck\nRunning percentage:  96.66666666666667\n#########################################################\nWestmorland—Kent  with index  30\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e0644c36e3dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mbad_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Brant North\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Brant South\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marticle_title\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbad_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwikipedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWikipediaPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwikipedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWikipediaPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, title, pageid, redirect, preload, original_title)\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Either a title or a pageid must be specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self, redirect, preload)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;31m# change the title and reload the whole object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredirects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'to'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, title, pageid, redirect, preload, original_title)\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Either a title or a pageid must be specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self, redirect, preload)\u001b[0m\n\u001b[1;32m    334\u001b[0m       \u001b[0mquery_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pageids'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpageid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wiki_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m_wiki_request\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m   \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPI_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mRATE_LIMIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;31m# Resolve redirects if allowed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_redirects\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;31m# Shuffle things around if there's history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;31m# Resolve redirects if allowed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_redirects\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;31m# Shuffle things around if there's history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mresolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                 resp = self.send(\n\u001b[0m\u001b[1;32m    238\u001b[0m                     \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    671\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             conn = connection.create_connection(\n\u001b[0m\u001b[1;32m    160\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/envs/elections/lib/python3.8/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LOOP THROUGH AND SCRAPE DATA\n",
    "total = 0\n",
    "approach_1 = 0\n",
    "approach_2 = 0\n",
    "electoral_districts = list(riding_dict.keys())\n",
    "\n",
    "# Process districts and extract successors\n",
    "with open('electoral_district_successors.csv', 'w', newline='') as successor_file:\n",
    "    successor_writer = csv.writer(successor_file)\n",
    "    num_districts = len(electoral_districts)\n",
    "    \n",
    "    for i in range(num_districts):\n",
    "        article_title = electoral_districts[i]\n",
    "        #article_title = electoral_districts[3]\n",
    "        #article_title = \"Digby and Annapolis\"Shelburne—Yarmouth—Clare\n",
    "        #article_title = \"Shelburne—Yarmouth—Clare\"\n",
    "        #article_title = \"New Westminster—Coquitlam\"\n",
    "        #article_title = \"New Westminster—Burnaby\"\n",
    "\n",
    "        print(\"#########################################################\")\n",
    "        print(article_title, \" with index \", i, \"/\", num_districts)\n",
    "\n",
    "       # if (i != 2 and i != 7):\n",
    "        riding_object = riding_dict.get(article_title)\n",
    "\n",
    "        # Extract dates and successors\n",
    "        bad_names = [\"Brant North\", \"Brant South\"]\n",
    "        if (article_title not in bad_names):\n",
    "            summary = wikipedia.WikipediaPage(article_title).summary\n",
    "\n",
    "            page = wikipedia.WikipediaPage(article_title)\n",
    "            html = page.html()\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            eras = scrape_table_information(soup)\n",
    "\n",
    "            if (eras):\n",
    "                riding_object.eras = eras\n",
    "                riding_object.approach = \"Table approach\"\n",
    "                approach_1 += 1\n",
    "            else:\n",
    "                print(\"FUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUck\")\n",
    "            \"\"\"\n",
    "            else:\n",
    "                eras = scrape_non_table_information(article_title)\n",
    "                riding_object.approach = \"Summary approach\"\n",
    "                approach_2 += 1\n",
    "            \"\"\"\n",
    "        total += 1\n",
    "        print(\"Running percentage: \", 100*approach_1/total)\n",
    "        \n",
    "\n",
    "        #successors = extract_successors(article_title)\n",
    "\n",
    "        # Add data to object\n",
    "        \"\"\"\n",
    "        riding_object.add_successors(successors)\n",
    "\n",
    "        #NOTE: ASSERT THAT THE DATES WORK OUT WHEN ADDING TO GRAPH\n",
    "        # Add dates\n",
    "        extractDates(article_title)\n",
    "\n",
    "\n",
    "        # Add edges in graph\n",
    "        for successor in successors:\n",
    "            successor_object = riding_dict.get(successor)\n",
    "            if (not successor_object is None):\n",
    "                successor_object.add_predecessor(article_title)\n",
    "                G.add_edge(riding_object, successor_object)\n",
    "        \n",
    "        if (len(successors) > 0):\n",
    "            successful += 1\n",
    "        \n",
    "        if (len(successors) == 0):\n",
    "            successors = [\"None found\"]\n",
    "        \"\"\"\n",
    "        \n",
    "        successor_contents = [article_title] + [(era.start, era.end, era.predecessors, era.successors) for era in eras]\n",
    "        successor_writer.writerow(successor_contents)\n",
    "        #break\n",
    "print(\"Percentage of ridings with at least one identified successor: \", 100*(approach_1 + approach_2)/total, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\ntotal = 0\\nsuccessful = 0\\n\\nwith open(\\'electoral_district_predecessors.csv\\', \\'w\\', newline=\\'\\') as predecessor_file:\\n    predecessor_writer = csv.writer(predecessor_file)\\n    \\n    for i in range(len(electoral_districts)):\\n        article_title = electoral_districts[i]\\n        riding_object = riding_dict.get(article_title)\\n        predecessors = riding_object.predecessors\\n\\n        if (len(predecessors) > 0):\\n            successful += 1\\n        \\n        if (len(predecessors) == 0):\\n            predecessors = [\"None found\"]\\n        \\n        predecessor_contents = [article_title] + predecessors\\n        predecessor_writer.writerow(predecessor_contents)\\n\\n        total += 1\\n        break\\n\\nprint(\"Percentage of ridings with at least one identified predecessor: \", 100*successful/total, \"%\")\\n'"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "\"\"\"\n",
    "total = 0\n",
    "successful = 0\n",
    "\n",
    "with open('electoral_district_predecessors.csv', 'w', newline='') as predecessor_file:\n",
    "    predecessor_writer = csv.writer(predecessor_file)\n",
    "    \n",
    "    for i in range(len(electoral_districts)):\n",
    "        article_title = electoral_districts[i]\n",
    "        riding_object = riding_dict.get(article_title)\n",
    "        predecessors = riding_object.predecessors\n",
    "\n",
    "        if (len(predecessors) > 0):\n",
    "            successful += 1\n",
    "        \n",
    "        if (len(predecessors) == 0):\n",
    "            predecessors = [\"None found\"]\n",
    "        \n",
    "        predecessor_contents = [article_title] + predecessors\n",
    "        predecessor_writer.writerow(predecessor_contents)\n",
    "\n",
    "        total += 1\n",
    "        break\n",
    "\n",
    "print(\"Percentage of ridings with at least one identified predecessor: \", 100*successful/total, \"%\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('elections': conda)",
   "language": "python",
   "name": "python38264bitelectionsconda9a5b9d1cf3d74687b599c4877bffd1c6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}